# Извлечение тегов (NER) с использованием модели BERT

## Описание

Данный проект решает задачу извлечения именованных сущностей (NER) из текста с использованием модели BERT. В качестве входных данных используется датасет `ner_datasetreference.csv`, который содержит предложения, разбитые на слова, и соответствующие теги, указывающие на тип каждого слова. Задача состоит в выделении интересующих нас тегов, с учетом дисбаланса слов с тегом "О", и обучении модели для автоматического определения тегов в тексте.
## Установка

1.  Клонируйте репозиторий на локальную машину:
```
git clone https://github.com/your_username/NER-using-BERT.git` 
```
2.  Перейдите в директорию проекта:
```
cd NER-using-BERT
``` 
    
3.  Установите необходимые зависимости:
```     
pip install -r requirements.txt
``` 
4. Запустите файл Jupyter Notebook 
`train_model.ipynb` 
    


## Метрика оценки

Для оценки качества обучения нейронной сети используется метрика accuracy, а так же кастомная accuracy. При этом тэги "О" исключаются при вычислении кастомной accuracy, чтобы избежать влияния дисбаланса классов на оценку качества модели.